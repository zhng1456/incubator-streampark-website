"use strict";(self.webpackChunkapache_streampark_website=self.webpackChunkapache_streampark_website||[]).push([[503],{3905:(e,n,i)=>{i.d(n,{Zo:()=>c,kt:()=>h});var t=i(7294);function o(e,n,i){return n in e?Object.defineProperty(e,n,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[n]=i,e}function r(e,n){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),i.push.apply(i,t)}return i}function a(e){for(var n=1;n<arguments.length;n++){var i=null!=arguments[n]?arguments[n]:{};n%2?r(Object(i),!0).forEach((function(n){o(e,n,i[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):r(Object(i)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(i,n))}))}return e}function l(e,n){if(null==e)return{};var i,t,o=function(e,n){if(null==e)return{};var i,t,o={},r=Object.keys(e);for(t=0;t<r.length;t++)i=r[t],n.indexOf(i)>=0||(o[i]=e[i]);return o}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)i=r[t],n.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(o[i]=e[i])}return o}var p=t.createContext({}),s=function(e){var n=t.useContext(p),i=n;return e&&(i="function"==typeof e?e(n):a(a({},n),e)),i},c=function(e){var n=s(e.components);return t.createElement(p.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},f=t.forwardRef((function(e,n){var i=e.components,o=e.mdxType,r=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),f=s(i),h=o,u=f["".concat(p,".").concat(h)]||f[h]||d[h]||r;return i?t.createElement(u,a(a({ref:n},c),{},{components:i})):t.createElement(u,a({ref:n},c))}));function h(e,n){var i=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var r=i.length,a=new Array(r);a[0]=f;var l={};for(var p in n)hasOwnProperty.call(n,p)&&(l[p]=n[p]);l.originalType=e,l.mdxType="string"==typeof e?e:o,a[1]=l;for(var s=2;s<r;s++)a[s]=i[s];return t.createElement.apply(null,a)}return t.createElement.apply(null,i)}f.displayName="MDXCreateElement"},4640:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>p,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>s});var t=i(7462),o=(i(7294),i(3905));const r={id:"hadoop-resource-integration",title:"Hadoop \u8d44\u6e90\u96c6\u6210",sidebar_position:3},a=void 0,l={unversionedId:"flink-k8s/hadoop-resource-integration",id:"flink-k8s/hadoop-resource-integration",title:"Hadoop \u8d44\u6e90\u96c6\u6210",description:"\u5728 Flink on K8s \u4e0a\u4f7f\u7528 Hadoop \u8d44\u6e90",source:"@site/i18n/zh-CN/docusaurus-plugin-content-docs/current/flink-k8s/3-hadoop-resource-integration.md",sourceDirName:"flink-k8s",slug:"/flink-k8s/hadoop-resource-integration",permalink:"/zh-CN/docs/flink-k8s/hadoop-resource-integration",draft:!1,editUrl:"https://github.com/apache/incubator-streampark-website/edit/dev/i18n/zh-CN/docusaurus-plugin-content-docs/current/flink-k8s/3-hadoop-resource-integration.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{id:"hadoop-resource-integration",title:"Hadoop \u8d44\u6e90\u96c6\u6210",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"K8S PVC \u8d44\u6e90\u4f7f\u7528",permalink:"/zh-CN/docs/flink-k8s/k8s-pvc-integration"}},p={},s=[{value:"\u5728 Flink on K8s \u4e0a\u4f7f\u7528 Hadoop \u8d44\u6e90",id:"\u5728-flink-on-k8s-\u4e0a\u4f7f\u7528-hadoop-\u8d44\u6e90",level:2},{value:"1\u3001HDFS",id:"1hdfs",level:4},{value:"i\u3001\u6dfb\u52a0 <code>shade jar</code>",id:"i\u6dfb\u52a0-shade-jar",level:5},{value:"ii\u3001\u6dfb\u52a0 core-site.xml \u548c hdfs-site.xml",id:"ii\u6dfb\u52a0-core-sitexml-\u548c-hdfs-sitexml",level:5},{value:"2\u3001Hive",id:"2hive",level:4},{value:"i\u3001\u6dfb\u52a0 hive \u76f8\u5173\u7684 jar",id:"i\u6dfb\u52a0-hive-\u76f8\u5173\u7684-jar",level:5},{value:"ii\u3001\u6dfb\u52a0 hive \u7684\u914d\u7f6e\u6587\u4ef6\uff08hive-site.xml\uff09",id:"ii\u6dfb\u52a0-hive-\u7684\u914d\u7f6e\u6587\u4ef6hive-sitexml",level:5},{value:"\u603b\u7ed3",id:"\u603b\u7ed3",level:4}],c={toc:s};function d(e){let{components:n,...i}=e;return(0,o.kt)("wrapper",(0,t.Z)({},c,i,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"\u5728-flink-on-k8s-\u4e0a\u4f7f\u7528-hadoop-\u8d44\u6e90"},"\u5728 Flink on K8s \u4e0a\u4f7f\u7528 Hadoop \u8d44\u6e90"),(0,o.kt)("p",null,"\u5728 StreamPark Flink-K8s runtime \u4e0b\u4f7f\u7528 Hadoop \u8d44\u6e90\uff0c\u5982 checkpoint \u6302\u8f7d HDFS\u3001\u8bfb\u5199 Hive \u7b49\uff0c\u5927\u6982\u6d41\u7a0b\u5982\u4e0b\uff1a"),(0,o.kt)("h4",{id:"1hdfs"},"1\u3001HDFS"),(0,o.kt)("p",null,"\u200b       \u5982\u9700\u5c06 flink on k8s \u76f8\u5173\u8d44\u6e90\u653e\u5728 HDFS \u4e2d\uff0c\u9700\u8981\u7ecf\u8fc7\u4ee5\u4e0b\u4e24\u4e2a\u6b65\u9aa4\uff1a"),(0,o.kt)("h5",{id:"i\u6dfb\u52a0-shade-jar"},"i\u3001\u6dfb\u52a0 ",(0,o.kt)("inlineCode",{parentName:"h5"},"shade jar")),(0,o.kt)("p",null,"\u200b           \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u4ece Docker \u4e0a pull \u7684 flink \u955c\u50cf\u662f\u4e0d\u5305\u62ec hadoop \u76f8\u5173\u7684 jar\uff0c\u8fd9\u91cc\u4ee5 flink:1.14.5-scala_2.12-java8 \u4e3a\u4f8b\uff0c\u5982\u4e0b\uff1a"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"[flink@ff]  /opt/flink-1.14.5/lib\n$ ls\nflink-csv-1.14.5.jar        flink-shaded-zookeeper-3.4.14.jar  log4j-api-2.17.1.jar\nflink-dist_2.12-1.14.5.jar  flink-table_2.12-1.14.5.jar        log4j-core-2.17.1.jar\nflink-json-1.14.5.jar       log4j-1.2-api-2.17.1.jar           log4j-slf4j-impl-2.17.1.jar\n")),(0,o.kt)("p",null,"\u200b         \u8fd9\u662f\u9700\u8981\u5c06 shade jar \u4e0b\u8f7d\u4e0b\u6765\uff0c\u7136\u540e\u653e\u5728 flink \u7684 lib \u76ee\u5f55\u4e0b\uff0c\u8fd9\u91cc \u4ee5hadoop2 \u4e3a\u4f8b\uff0c\u4e0b\u8f7d ",(0,o.kt)("inlineCode",{parentName:"p"},"flink-shaded-hadoop-2-uber"),"\uff1a",(0,o.kt)("a",{parentName:"p",href:"https://repo1.maven.org/maven2/org/apache/flink/flink-shaded-hadoop-2-uber/2.7.5-9.0/flink-shaded-hadoop-2-uber-2.7.5-9.0.jar"},"https://repo1.maven.org/maven2/org/apache/flink/flink-shaded-hadoop-2-uber/2.7.5-9.0/flink-shaded-hadoop-2-uber-2.7.5-9.0.jar")),(0,o.kt)("p",null,"\u200b\t\u53e6\u5916\uff0c\u53ef\u4ee5\u5c06 shade jar \u4ee5\u4f9d\u8d56\u7684\u65b9\u5f0f\u5728 StreamPark \u7684\u4efb\u52a1\u914d\u7f6e\u4e2d\u7684",(0,o.kt)("inlineCode",{parentName:"p"},"Dependency")," \u8fdb\u884c\u4f9d\u8d56\u914d\u7f6e\uff0c\u5982\u4e0b\u914d\u7f6e\uff1a"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-xml"},"<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-shaded-hadoop-2-uber</artifactId>\n    <version>2.7.5-9.0</version>\n    <scope>provided</scope>\n</dependency>\n")),(0,o.kt)("h5",{id:"ii\u6dfb\u52a0-core-sitexml-\u548c-hdfs-sitexml"},"ii\u3001\u6dfb\u52a0 core-site.xml \u548c hdfs-site.xml"),(0,o.kt)("p",null,"\u200b            \u6709\u4e86 shade jar \u8fd8\u9700\u8981\u76f8\u5e94\u7684\u914d\u7f6e\u6587\u4ef6\u53bb\u627e\u5230 hadoop \u5730\u5740\uff0c\u8fd9\u91cc\u4e3b\u8981\u6d89\u53ca\u5230\u4e24\u4e2a\u914d\u7f6e\u6587\u4ef6\uff1acore-site.xml\u548chdfs-site.xml\uff0c\u901a\u8fc7 flink \u7684\u6e90\u7801\u5206\u6790(\u6d89\u53ca\u5230\u7684\u7c7b\u4e3b\u8981\u662f\uff1aorg.apache.flink.kubernetes.kubeclient.parameters.AbstractKubernetesParameters)\uff0c\u8be5\u4e24\u6587\u4ef6\u6709\u56fa\u5b9a\u7684\u52a0\u8f7d\u987a\u5e8f\uff0c\u5982\u4e0b\uff1a"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-java"},'// \u5bfb\u627e hadoop \u914d\u7f6e\u6587\u4ef6\u7684\u6d41\u7a0b\n// 1\u3001\u5148\u53bb\u5bfb\u5728\u662f\u5426\u6dfb\u52a0\u4e86\u53c2\u6570\uff1akubernetes.hadoop.conf.config-map.name\n@Override\npublic Optional<String> getExistingHadoopConfigurationConfigMap() {\n    final String existingHadoopConfigMap =\n            flinkConfig.getString(KubernetesConfigOptions.HADOOP_CONF_CONFIG_MAP);\n    if (StringUtils.isBlank(existingHadoopConfigMap)) {\n        return Optional.empty();\n    } else {\n        return Optional.of(existingHadoopConfigMap.trim());\n    }\n}\n\n@Override\npublic Optional<String> getLocalHadoopConfigurationDirectory() {\n    // 2\u3001\u5982\u679c\u6ca1\u67091\u4e2d\u6307\u5b9a\u7684\u53c2\u6570\uff0c\u67e5\u627e\u63d0\u4ea4 native \u547d\u4ee4\u7684\u672c\u5730\u73af\u5883\u662f\u5426\u6709\u73af\u5883\u53d8\u91cf\uff1aHADOOP_CONF_DIR\n    final String hadoopConfDirEnv = System.getenv(Constants.ENV_HADOOP_CONF_DIR);\n    if (StringUtils.isNotBlank(hadoopConfDirEnv)) {\n        return Optional.of(hadoopConfDirEnv);\n    }\n    // 3\u3001\u5982\u679c\u6ca1\u67092\u4e2d\u73af\u5883\u53d8\u91cf\uff0c\u518d\u7ee7\u7eed\u770b\u662f\u5426\u6709\u73af\u5883\u53d8\u91cf\uff1aHADOOP_HOME\n    final String hadoopHomeEnv = System.getenv(Constants.ENV_HADOOP_HOME);\n    if (StringUtils.isNotBlank(hadoopHomeEnv)) {\n        // Hadoop 2.x\n        final File hadoop2ConfDir = new File(hadoopHomeEnv, "/etc/hadoop");\n        if (hadoop2ConfDir.exists()) {\n            return Optional.of(hadoop2ConfDir.getAbsolutePath());\n        }\n\n        // Hadoop 1.x\n        final File hadoop1ConfDir = new File(hadoopHomeEnv, "/conf");\n        if (hadoop1ConfDir.exists()) {\n            return Optional.of(hadoop1ConfDir.getAbsolutePath());\n        }\n    }\n\n    return Optional.empty();\n}\n\nfinal List<File> hadoopConfigurationFileItems = getHadoopConfigurationFileItems(localHadoopConfigurationDirectory.get());\n// \u5982\u679c\u6ca1\u6709\u627e\u52301\u30012\u30013\u8bf4\u660e\u6ca1\u6709 hadoop \u73af\u5883\nif (hadoopConfigurationFileItems.isEmpty()) {\n    LOG.warn("Found 0 files in directory {}, skip to mount the Hadoop Configuration ConfigMap.", localHadoopConfigurationDirectory.get());\n    return flinkPod;\n}\n//\u5982\u679c2\u6216\u80053\u5b58\u5728\uff0c\u4f1a\u5728\u8def\u5f84\u4e0b\u67e5\u627e core-site.xml \u548c hdfs-site.xml \u6587\u4ef6\nprivate List<File> getHadoopConfigurationFileItems(String localHadoopConfigurationDirectory) {\n    final List<String> expectedFileNames = new ArrayList<>();\n    expectedFileNames.add("core-site.xml");\n    expectedFileNames.add("hdfs-site.xml");\n\n    final File directory = new File(localHadoopConfigurationDirectory);\n    if (directory.exists() && directory.isDirectory()) {\n        return Arrays.stream(directory.listFiles())\n                .filter(\n                        file ->\n                                file.isFile()\n                                        && expectedFileNames.stream()\n                                                .anyMatch(name -> file.getName().equals(name)))\n                .collect(Collectors.toList());\n    } else {\n        return Collections.emptyList();\n    }\n}\n// \u5982\u679c\u627e\u5230\u4e0a\u8ff0\u6587\u4ef6\uff0c\u8bf4\u660e\u6709 hadoop \u7684\u73af\u5883\uff0c\u5c06\u4f1a\u628a\u4e0a\u8ff0\u4e24\u4e2a\u6587\u4ef6\u89e3\u6790\u4e3a kv \u5bf9\uff0c\u7136\u540e\u6784\u5efa\u6210\u4e00\u4e2a ConfigMap\uff0c\u540d\u5b57\u547d\u540d\u89c4\u5219\u5982\u4e0b\uff1a\npublic static String getHadoopConfConfigMapName(String clusterId) {\n    return Constants.HADOOP_CONF_CONFIG_MAP_PREFIX + clusterId;\n}\n')),(0,o.kt)("h4",{id:"2hive"},"2\u3001Hive"),(0,o.kt)("p",null,"\u200b        \u5c06\u6570\u636e sink \u5230 hive\uff0c\u6216\u8005\u4ee5 hive \u7684 metastore \u4f5c\u4e3a flink \u7684\u5143\u6570\u636e\uff0c\u90fd\u9700\u8981\u6253\u901a flink \u5230 hive \u7684\u8def\u5f84\uff0c\u540c\u6837\u9700\u8981\u7ecf\u8fc7\u4e00\u4e0b\u4e24\u4e2a\u6b65\u9aa4\uff1a"),(0,o.kt)("h5",{id:"i\u6dfb\u52a0-hive-\u76f8\u5173\u7684-jar"},"i\u3001\u6dfb\u52a0 hive \u76f8\u5173\u7684 jar"),(0,o.kt)("p",null,"\u200b\t     \u5982\u4e0a\u6240\u8ff0\uff0c\u9ed8\u8ba4 flink \u955c\u50cf\u662f\u4e0d\u5305\u62ec hive \u76f8\u5173\u7684 jar\uff0c\u9700\u8981\u5c06 hive \u76f8\u5173\u7684\u5982\u4e0b\u4e09\u4e2a jar \u653e\u5728 flink \u7684 lib \u76ee\u5f55\u4e0b\uff0c\u8fd9\u91cc\u4ee5 hive 2.3.6 \u7248\u672c\u4e3a\u4f8b\uff1a"),(0,o.kt)("p",null,"\u200b                a\u3001",(0,o.kt)("inlineCode",{parentName:"p"},"hive-exec"),"\uff1a",(0,o.kt)("a",{parentName:"p",href:"https://repo1.maven.org/maven2/org/apache/hive/hive-exec/2.3.6/hive-exec-2.3.6.jar"},"https://repo1.maven.org/maven2/org/apache/hive/hive-exec/2.3.6/hive-exec-2.3.6.jar")),(0,o.kt)("p",null,"\u200b                b\u3001",(0,o.kt)("inlineCode",{parentName:"p"},"flink-connector-hive"),"\uff1a",(0,o.kt)("a",{parentName:"p",href:"https://repo1.maven.org/maven2/org/apache/flink/flink-connector-hive_2.12/1.14.5/flink-connector-hive_2.12-1.14.5.jar"},"https://repo1.maven.org/maven2/org/apache/flink/flink-connector-hive_2.12/1.14.5/flink-connector-hive_2.12-1.14.5.jar")),(0,o.kt)("p",null,"\u200b                c\u3001",(0,o.kt)("inlineCode",{parentName:"p"},"flink-sql-connector-hive"),"\uff1a",(0,o.kt)("a",{parentName:"p",href:"https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-hive-2.3.6_2.12/1.14.5/flink-sql-connector-hive-2.3.6_2.12-1.14.5.jar"},"https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-hive-2.3.6_2.12/1.14.5/flink-sql-connector-hive-2.3.6_2.12-1.14.5.jar")),(0,o.kt)("p",null,"\u200b               \u540c\u6837\uff0c\u4e5f\u53ef\u4ee5\u5c06\u4e0a\u8ff0 hive \u76f8\u5173 jar \u4ee5\u4f9d\u8d56\u7684\u65b9\u5f0f\u5728 StreamPark \u7684\u4efb\u52a1\u914d\u7f6e\u4e2d\u7684",(0,o.kt)("inlineCode",{parentName:"p"},"Dependency")," \u8fdb\u884c\u4f9d\u8d56\u914d\u7f6e\uff0c\u8fd9\u91cc\u4e0d\u518d\u8d58\u8ff0\u3002"),(0,o.kt)("h5",{id:"ii\u6dfb\u52a0-hive-\u7684\u914d\u7f6e\u6587\u4ef6hive-sitexml"},"ii\u3001\u6dfb\u52a0 hive \u7684\u914d\u7f6e\u6587\u4ef6\uff08hive-site.xml\uff09"),(0,o.kt)("p",null,"\u200b\t       \u548c hdfs \u6240\u4e0d\u540c\u7684\u662f\uff0cflink \u6e90\u7801\u4e2d\u5e76\u6ca1\u6709 hive \u7684\u914d\u7f6e\u6587\u4ef6\u7684\u9ed8\u8ba4\u7684\u52a0\u8f7d\u65b9\u5f0f\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u8005\u624b\u52a8\u6dfb\u52a0 hive \u7684\u914d\u7f6e\u6587\u4ef6\uff0c\u8fd9\u91cc\u4e3b\u8981\u91c7\u7528\u4e09\u79cd\u65b9\u5f0f\uff1a"),(0,o.kt)("p",null,"\u200b\t\ta\u3001\u5c06 hive-site.xml \u6253\u5728 flink \u7684\u81ea\u5b9a\u4e49\u955c\u50cf\u4e4b\u4e2d\uff0c\u4e00\u822c\u5efa\u8bae\u653e\u5728\u955c\u50cf\u91cc\u7684",(0,o.kt)("inlineCode",{parentName:"p"},"/opt/flink/"),"\u76ee\u5f55\u4e4b\u4e0b"),(0,o.kt)("p",null,"\u200b\t\tb\u3001\u5c06 hive-site.xml \u653e\u5728\u8fdc\u7aef\u7684\u5b58\u50a8\u7cfb\u7edf\u4e4b\u540e\uff0c\u4f8b\u5982 HDFS\uff0c\u5728\u4f7f\u7528\u7684\u65f6\u5019\u8fdb\u884c\u52a0\u8f7d"),(0,o.kt)("p",null,"\u200b\t\tc\u3001\u5c06 hive-site.xml \u4ee5 ConfigMap \u7684\u5f62\u5f0f\u6302\u8f7d\u5728 k8s \u4e4b\u4e2d\uff0c\u5efa\u8bae\u4f7f\u7528\u6b64\u79cd\u65b9\u5f0f\uff0c\u5982\u4e0b\uff1a"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-shell"},"# 1\u3001\u5728\u6307\u5b9a\u7684 ns \u4e2d\u6302\u8f7d\u6307\u5b9a\u4f4d\u7f6e\u7684 hive-site.xml\nkubectl create cm hive-conf --from-file=hive-site.xml -n flink-test\n# 2\u3001\u67e5\u770b\u6302\u8f7d\u5230 k8s \u4e2d\u7684 hive-site.xml\nkubectl describe cm hive-conf -n flink-test \n# 3\u3001\u5c06\u6b64 cm \u6302\u8f7d\u5230\u5bb9\u5668\u5185\u6307\u5b9a\u7684\u76ee\u5f55\nspec:\n  containers:\n    - name: flink-main-container\n      volumeMounts:\n        - mountPath: /opt/flink/hive\n          name: hive-conf\n  volumes:\n    - name: hive-conf\n      configMap:\n        name: hive-conf\n        items:\n          - key: hive-site.xml\n            path: hive-site.xml\n")),(0,o.kt)("h4",{id:"\u603b\u7ed3"},"\u603b\u7ed3"),(0,o.kt)("p",null,"\u200b        \u901a\u8fc7\u4ee5\u4e0a\u7684\u65b9\u5f0f\u4fbf\u53ef\u4ee5\u5c06 flink \u548c hadoop\u3001hive \u6253\u901a\uff0c\u6b64\u65b9\u6cd5\u53ef\u63a8\u5e7f\u81f3\u4e00\u822c\uff0c\u5373 flink \u4e0e\u5916\u90e8\u7cfb\u7edf\u5982redis\u3001mongo \u7b49\u8fde\u901a\uff0c\u4e00\u822c\u9700\u8981\u5982\u4e0b\u4e24\u4e2a\u6b65\u9aa4\uff1a"),(0,o.kt)("p",null,"\u200b        i\u3001\u52a0\u8f7d\u6307\u5b9a\u5916\u90e8\u670d\u52a1\u7684 connector jar"),(0,o.kt)("p",null,"\u200b\tii\u3001\u5982\u679c\u6709\uff0c\u52a0\u8f7d\u6307\u5b9a\u7684\u914d\u7f6e\u6587\u4ef6\u5230 flink \u7cfb\u7edf\u4e4b\u4e2d"))}d.isMDXComponent=!0}}]);